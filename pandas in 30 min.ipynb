{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "# **PANDAS**   IN 30 MIN                                                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "#### Author -   **Wes McKinney**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presented by Manoj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ###### Developer Wes McKinney started working on pandas in 2008 while at AQR Capital Management out of the need for a high performance, flexible tool to perform quantitative analysis on financial data. Before leaving AQR he was able to convince management to allow him to open source the library.\n",
    "* ###### Another AQR employee, Chang She, joined the effort in 2012 as the second major contributor to the library.\n",
    "* ###### In 2015, pandas signed on as a fiscally sponsored project of NumFOCUS, a 501(c)(3) nonprofit charity in the United States."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <ins>**INTRODUCTION TO PANDAS** </ins> :\n",
    "\n",
    "### PANDAS is used in different ways\n",
    "1. DataFrame object for data manipulation with integrated indexing.\n",
    "2. Tools for reading and writing data between in-memory data structures and different file formats.\n",
    "3. Data alignment and integrated handling of missing data.\n",
    "4. Reshaping and pivoting of data sets.\n",
    "5. Label-based slicing, fancy indexing, and subsetting of large data sets.\n",
    "6. Data structure column insertion and deletion.\n",
    "7. Group by engine allowing split-apply-combine operations on data sets.\n",
    "8. Data set merging and joining.\n",
    "9. Hierarchical axis indexing to work with high-dimensional data in a lower-dimensional data structure.\n",
    "10. Time series-functionality: Date range generation and frequency conversion, moving window statistics, moving window linear regressions, date shifting and lagging.\n",
    "11. Provides data filtration.\n",
    "###### The library is highly optimized for performance, with critical code paths written in Cython or C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "### Here we are going to solve some problems using \"pandas\" ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class=\"alert alert-success\"><font color=green>Import pandas and numpy</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class=\"alert alert-success\"><font color=blue>Object Creation</font>\n",
    "**Creating a Series by passing a list of values, letting pandas create a default integer index:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_series = pd.Series([1, 3, 5, np.nan, 6, 8])\n",
    "print(number_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Creating a DataFrame by passing a NumPy array, with a datetime index and labeled columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('20130101', periods=6)\n",
    "#print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list('ABCD'))\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Creating a DataFrame by passing a dict of objects that can be converted to series-like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({\"A\": pd.Timestamp('20130301'),\n",
    "                 \"B\": ['Hyderabad','Chennai','Bangalore','Mumbai']})\n",
    "#print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class=\"alert alert-success\"> <font color=blue>Viewing data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class=\"alert alert-success\"><font color=blue>Selection</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <font color=red>Selection by label</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[dates[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['A', 'B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[dates[0], 'A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <font color=red>Selectionby position</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3:5, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[1, 2, 4], [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <font color=red>Boolean indexing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.A > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using the isin() method for filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2['E'] = ['one', 'one', 'two', 'three', 'four', 'three']\n",
    "#print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['E'].isin(['two', 'four'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class=\"alert alert-success\"> <font color=blue>Missing data</font>\n",
    "**pandas primarily uses the value np.nan to represent missing data. It is by default not included in computations. See the Missing Data section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + ['E'])\n",
    "df1.loc[dates[0]:dates[1], 'E'] = 1\n",
    "#print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.fillna(value=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class=\"alert alert-success\"> <font color=blue>Operations</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class=\"alert alert-success\"> <font color=blue>Apply function</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.apply(np.cumsum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### String Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.Series(['Manoj', 'Srinivas', 'karthik', 'RaMEsh', 'SUREsh', np.nan, 'lion', 'dog', 'cat'])\n",
    "#names.str.upper()\n",
    "#names.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <div class=\"alert alert-success\"><font color=blue>Merge</font> \n",
    "<font color=red>**Concat**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(10, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Break it in to pieces\n",
    "pieces = [df[:3], df[3:7], df[7:]]\n",
    "#pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(pieces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <font color=red>**Join**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key': ['foo', 'foo'], 'lval': [1, 2]})\n",
    "\n",
    "right = pd.DataFrame({'key': ['foo', 'foo'], 'rval': [4, 5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(right)\n",
    "#print(left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left, right, on='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key': ['foo', 'bar'], 'lval': [1, 2]})\n",
    "right = pd.DataFrame({'key': ['foo', 'bar'], 'rval': [4, 5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left, right, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class=\"alert alert-success\"> <font color=blue>Append</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(8, 4), columns=['A', 'B', 'C', 'D'])\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df.iloc[3]\n",
    "df.append(s, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class=\"alert alert-success\"> <font color=blue>Grouping</font>\n",
    "**By “group by” we are referring to a process involving one or more of the following steps:**\n",
    "\n",
    "* Splitting the data into groups based on some criteria\n",
    "* Applying a function to each group independently\n",
    "* Combining the results into a data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': ['foo', 'bar', 'foo', 'bar',\n",
    "                         'foo', 'bar', 'foo', 'foo'],\n",
    "                      'B': ['one', 'one', 'two', 'three',\n",
    "                             'two', 'two', 'one', 'three'],\n",
    "                       'C': np.random.randn(8),\n",
    "                       'D': np.random.randn(8)})\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('A').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['A', 'B']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <div class=\"alert alert-success\"> <font color=blue>Pivot tables</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': ['one', 'one', 'two', 'three'] * 3,\n",
    "                   'B': ['A', 'B', 'C'] * 4,\n",
    "                   'C': ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2,\n",
    "                   'D': np.random.randn(12),\n",
    "                   'E': np.random.randn(12)})\n",
    "#print(df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class=\"alert alert-success\"><font color=blue>Plotting</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(np.random.randn(1000),\n",
    "                   index=pd.date_range('1/1/2000', periods=1000))\n",
    "#print(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = ts.cumsum()\n",
    "#print(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index,\n",
    "                     columns=['A', 'B', 'C', 'D'])\n",
    "#print(df)    \n",
    "df = df.cumsum()\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div class=\"alert alert-success\"><font color=blue>Getting data in/out</font>\n",
    "<font color=red>**CSV**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('foo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('foo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <font color=red>**HDF5**</font>\n",
    "\n",
    "* ***HDF5 for Python***\n",
    "* The h5py package is a Pythonic interface to the HDF5 binary data format.\n",
    "\n",
    "HDF5 lets you store huge amounts of numerical data, and easily manipulate that data from NumPy. For example, you can slice into multi-terabyte datasets stored on disk, as if they were real NumPy arrays. Thousands of datasets can be stored in a single file, categorized and tagged however you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf('foo.h5', 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_hdf('foo.h5', 'df')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
